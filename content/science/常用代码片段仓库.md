+++
title =  "常用代码片段仓库 "
date = 2020-02-06T12:17:57+08:00
draft =  false
share = true	# set false to hide share buttons
tags = ["python"]

categories = ["技能杂记"]

toc = true
summary= " 编程过程中有很多重复的代码片段，结构比较固定，也记不住，笔记在这里，方便回来查找复制。不定时更新中...."
img = "images/code.png"
+++


## 更新博客使用，markdown头文件代码：

```text
+++
author = "Angyi"
comments = true # set false to hide Disqus
date  = 2019-12-13T12:17:57+08:00
draft = false
share = true    # set false to hide share buttons
tags = ["RNN","Deeplearning"]
series = ["ai"] # python ai others ocean
categories = ["深度学习"]
## python 深度学习 机器学习 其他 数据分析 海洋大气
toc = true
summary= "首页概述"
title = " 标题 "
img = "images/rnn7.png"
+++
```
## 读取nc文件
```python
import netCDF4
from netCDF4 import Dataset
nc_obj=Dataset('e:\\P_CLDAS_RE01_EA16_PRE_HOUR_2015010101.nc')
#查看nc文件有些啥东东
print(nc_obj)
print('---------------------------------------')
#查看nc文件中的变量
print(nc_obj.variables.keys())
for i in nc_obj.variables.keys():
    print(i)
print('---------------------------------------')
#查看每个变量的信息
print(nc_obj.variables['LAT'])
print(nc_obj.variables['LON'])
print(nc_obj.variables['PRCP'])
print('---------------------------------------')
#查看每个变量的属性
print(nc_obj.variables['LAT'].ncattrs())
print(nc_obj.variables['LON'].ncattrs())
print(nc_obj.variables['PRCP'].ncattrs())
print(nc_obj.variables['LAT'].units)
print(nc_obj.variables['LON'].units)
print(nc_obj.variables['PRCP']._Fillvalue)
print('---------------------------------------')
#读取数据值
lat=(nc_obj.variables['LAT'][:])
lon=(nc_obj.variables['LON'][:])
prcp=(nc_obj.variables['PRCP'][:])
print(lat)
print(lon)
print('---------------******-------------------')
print(prcp)
```

## Matlab 输出高清图片代码

```matlab
print(gcf,'-r600','-dpng','filename')
```

## 我不等于我自己

在数据处理的时候，曾经因为这个问题搞到我泪流满面。


![](https://github.com/Flionay/flionay.github.io/blob/master/images/bed/wobudengyuwoziji.jpg?raw=true)

我不等于我自己？？？


```python
>>> np.nan == np.nan
False
```


这也是变量≠自身的一个特例，因此使用这个性质可以判断这个数是否为nan

## Pandas 删除某一行


```python
input_dataset = input_dataset.drop(index=(input_dataset.loc[(input_dataset['pressure'].isnull())].index))
input_dataset = input_dataset.drop(index=(input_dataset.loc[(input_dataset['chla_a'].isnull())].index))
input_dataset = input_dataset.drop(index=(input_dataset.loc[(input_dataset['chla_a']<0.05)].index))
input_dataset = input_dataset.drop(index=(input_dataset.loc[(input_dataset['chla_a']>3.5)].index))
input_dataset = input_dataset.drop(index=(input_dataset.loc[(input_dataset['pressure']>400)].index))

```
## pip 选择清华镜像

```python
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package
```

## torch ANN基本框架---感谢林同学

```python

import pandas as pd
from sklearn import preprocessing
import numpy as np
import torch
import scipy
import torch.nn.functional as F
import torch.utils.data as Data
from torch.autograd import Variable
import matplotlib.pyplot as plt


learning_rate = 0.01
EPOCH  = 5000
slice_data = 0.6


class Net(torch.nn.Module):
    def __init__(self, n_input, n_hidden, n_output):
        super(Net, self).__init__()
        self.hidden = torch.nn.Linear(n_input, n_hidden)   # hidden layer
        self.out = torch.nn.Linear(n_hidden, n_output)   # output layer

    def forward(self, x):
        x = torch.sigmoid(self.hidden(x))
        x = self.out(x)
        return x



class Train():
    def __init__(self, net, loss_function, optimizer, traindata, trainlabel, testdata, testlabel, epoch):
        self.net = net
        self.loss_function = loss_function
        self.optimizer = optimizer
        self.traindata = traindata
        self.trainlabel = trainlabel
        self.testdata = testdata
        self.testlabel = testlabel
        self.epoch = epoch
    def train(self):
        for epo in range(self.epoch):
            out_put = self.net(self.traindata)
            loss = criterion(out_put, self.trainlabel)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            print(epo, loss.data)
            if epo % 20 == 0:
                torch.save(net, 'net2.pkl')



    def test(self):
        model = torch.load('net2.pkl')
        optimizer.zero_grad()
        out_put = model(self.testdata)
        loss = criterion(out_put, self.testlabel)
        print("测试集平均误差{:.2f}".format(loss))
        plt.cla()
        y1 = out_put.detach().numpy().squeeze().flatten()
        y2 = self.testlabel.detach().numpy().squeeze().flatten()
        plt.plot(y1[0:1000], color='cyan', label='predict')
        plt.plot(y2[0:1000], label='true')
        plt.show()


if __name__ == '__main__':
    input_data = pd.read_csv('input.csv')
    output_data = pd.read_csv('output.csv')

    input_data = input_data.drop(columns=['Unnamed: 0'])  # ['Unnamed: 0','chla_a','latitude','longitude','days'])
    output_data = output_data.drop(columns='Unnamed: 0')

    input_data = preprocessing.scale(input_data, axis=0)
    output_data = preprocessing.scale(output_data, axis=0)
    input_data = np.array(input_data)
    output_data = np.array(output_data)
    output_data = output_data.reshape((output_data.shape[0], 1))

    # training
    input_data = input_data.astype(np.float32)
    output_data = output_data.astype(np.float32)
    
	# 转换成tensor
    #x = torch.from_numpy(input_data)
    #y = torch.from_numpy(output_data)

    slices = int(input_data.shape[0] * slice_data)
    traindata = input_data[0:slices,:]
    traindata = Variable(torch.Tensor(traindata))
    trainlabel = Variable(torch.Tensor(output_data[0:slices]))
    testdata = input_data[slices:-1,:]
    testdata = Variable(torch.Tensor(testdata))
    testlabel = Variable(torch.Tensor(output_data[slices:-1]))
    #torch_dataset = Data.TensorDataset(x[0:slices, :], y[0:slices, :])
    #torch_dataset_test = Data.TensorDataset(x[slices:-1, :], y[slices:-1, :])


    net = Net(n_input=5, n_hidden=15, n_output=1)
    optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)  # SGD: 随机梯度下降
    criterion = torch.nn.MSELoss()
    training = Train(net, criterion, optimizer, traindata, trainlabel, testdata, testlabel, EPOCH)
    training.train()
    training.test()
```





