<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ai on Angyi</title>
    <link>https://example.com/series/ai/</link>
    <description>Recent content in ai on Angyi</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zn-Hans</language>
    <lastBuildDate>Sun, 20 Oct 2019 19:59:58 +0800</lastBuildDate>
    
	<atom:link href="https://example.com/series/ai/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>解密卷积神经网络 </title>
      <link>https://example.com/cnn_report-1/</link>
      <pubDate>Sun, 20 Oct 2019 19:59:58 +0800</pubDate>
      
      <guid>https://example.com/cnn_report-1/</guid>
      <description>卷积神经网络的原理初步理解。</description>
    </item>
    
    <item>
      <title>决策树和随机森林代码实现</title>
      <link>https://example.com/%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</link>
      <pubDate>Sun, 29 Sep 2019 17:35:00 +0800</pubDate>
      
      <guid>https://example.com/%E5%86%B3%E7%AD%96%E6%A0%91%E5%92%8C%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/</guid>
      <description>决策树和随机森林的代码实现，采用面向对象的编程方式。</description>
    </item>
    
    <item>
      <title>决策树和随机森林</title>
      <link>https://example.com/%E5%86%B3%E7%AD%96%E6%A0%91/</link>
      <pubDate>Sat, 28 Sep 2019 13:56:00 +0800</pubDate>
      
      <guid>https://example.com/%E5%86%B3%E7%AD%96%E6%A0%91/</guid>
      <description>决策树和随机森林基本思想以及构造流程。</description>
    </item>
    
    <item>
      <title>正则化代码实现</title>
      <link>https://example.com/%E7%AC%AC%E4%BA%8C%E9%97%A8%E8%AF%BE_%E4%BD%9C%E4%B8%9A/</link>
      <pubDate>Fri, 16 Aug 2019 17:00:16 +0800</pubDate>
      
      <guid>https://example.com/%E7%AC%AC%E4%BA%8C%E9%97%A8%E8%AF%BE_%E4%BD%9C%E4%B8%9A/</guid>
      <description>在初始化过程中进行改进，来避免梯度爆炸和梯度消失问题。
 在前向传播和反向传播中进行正则化，来避免过拟合问题。</description>
    </item>
    
    <item>
      <title>吴恩达教程-第二门课笔记</title>
      <link>https://example.com/%E7%AC%AC%E4%BA%8C%E9%97%A8%E8%AF%BE%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 16 Aug 2019 15:35:38 +0800</pubDate>
      
      <guid>https://example.com/%E7%AC%AC%E4%BA%8C%E9%97%A8%E8%AF%BE%E7%AC%94%E8%AE%B0/</guid>
      <description>改善深层神经网络：超参数调试，正则化以及优化</description>
    </item>
    
    <item>
      <title>手写浅层神经网络</title>
      <link>https://example.com/%E6%89%8B%E5%86%99%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Wed, 07 Aug 2019 13:12:16 +0800</pubDate>
      
      <guid>https://example.com/%E6%89%8B%E5%86%99%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</guid>
      <description>虽然你知道神经网络，但是给你一张黑板，你能从开始推到结尾吗？如果不能，点进来
 对梯度下降法，参数反向传播更新的代码实现。只有自己亲自代码实现，那才算真正会。</description>
    </item>
    
    <item>
      <title>神经网络的激活函数和向量化代码应用</title>
      <link>https://example.com/notebook_01/</link>
      <pubDate>Wed, 24 Jul 2019 21:16:30 +0800</pubDate>
      
      <guid>https://example.com/notebook_01/</guid>
      <description>有时候看很多论文，视频教程还是无法深刻理解这些东西是如何实现的，我的宗旨一向都是  代码说话  ，只有亲自代码实现，才能真正掌握。</description>
    </item>
    
    <item>
      <title>1.3：神经网络的编程基础</title>
      <link>https://example.com/lesson1-week3/</link>
      <pubDate>Thu, 18 Jul 2019 12:27:12 +0800</pubDate>
      
      <guid>https://example.com/lesson1-week3/</guid>
      <description>【Basics of Neural Network programming】第一门课第三周；1.神经网络多样本具体计算 2多种激活函数对比.</description>
    </item>
    
    <item>
      <title>1.2.4-end：神经网络的编程基础</title>
      <link>https://example.com/lesson1-week2/</link>
      <pubDate>Wed, 17 Jul 2019 12:27:12 +0800</pubDate>
      
      <guid>https://example.com/lesson1-week2/</guid>
      <description>【Basics of Neural Network programming】第一门课第二周4-end；1.导数计算细节 2向量化编程.</description>
    </item>
    
    <item>
      <title>1.2.1-4：神经网络的编程基础</title>
      <link>https://example.com/lesson1_week2_1_4/</link>
      <pubDate>Tue, 16 Jul 2019 20:27:12 +0800</pubDate>
      
      <guid>https://example.com/lesson1_week2_1_4/</guid>
      <description>【Basics of Neural Network programming】第一门课第二周1-4小节；   1. 基本案例，辨识猫，二分类模型      2.  逻辑回归     3. 损失函数      4. 梯度下降法</description>
    </item>
    
    <item>
      <title>Machine Learning interview</title>
      <link>https://example.com/%E9%87%87%E8%AE%BF/</link>
      <pubDate>Wed, 10 Jul 2019 09:59:58 +0800</pubDate>
      
      <guid>https://example.com/%E9%87%87%E8%AE%BF/</guid>
      <description>榜样的力量-吴恩达采访人工智能大师实录</description>
    </item>
    
    <item>
      <title>第一门课 神经网络和深度学习(Neural Networks and Deep Learning)</title>
      <link>https://example.com/lesson1-week1/</link>
      <pubDate>Thu, 14 Mar 2019 09:59:58 +0800</pubDate>
      
      <guid>https://example.com/lesson1-week1/</guid>
      <description>神经网络和深度学习的基本介绍和入门案例</description>
    </item>
    
  </channel>
</rss>